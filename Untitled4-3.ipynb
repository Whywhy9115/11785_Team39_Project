{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T4ZGbYzat0M2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV5SfvwTtyEI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
        "from itertools import product\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dropout, Bidirectional, LSTM, Dense, TimeDistributed, Multiply, Softmax, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "config = {\n",
        "    'sequence_length': 60,\n",
        "    'val_size': 100,\n",
        "    'test_size': 250,\n",
        "    'epochs': 100,\n",
        "    'batch_size': 32,\n",
        "    'random_state': 42\n",
        "}"
      ],
      "metadata": {
        "id": "iqaYnkXnt70e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Load data and compute indicators ===\n",
        "try:\n",
        "    data = yf.download('000001.SS', start='2010-01-01', end='2025-01-01', auto_adjust=True)\n",
        "    if data.empty:\n",
        "        raise ValueError(\"No data downloaded\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading data: {e}\")\n",
        "    exit(1)\n",
        "print(len(data))\n",
        "\n",
        "data = data[~data.index.duplicated(keep='first')]\n",
        "data = data.dropna()\n",
        "\n",
        "\n",
        "data['return'] = data['Close'].pct_change()\n",
        "data['target_return'] = data['return'].shift(-1)\n",
        "\n",
        "\n",
        "data['EMA5'] = data['Close'].ewm(span=5, adjust=False).mean()\n",
        "data['EMA10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
        "\n",
        "\n",
        "data['TR'] = np.maximum(\n",
        "    data['High'] - data['Low'],\n",
        "    np.maximum(\n",
        "        abs(data['High'] - data['Close'].shift(1)),\n",
        "        abs(data['Low'] - data['Close'].shift(1))\n",
        "    )\n",
        ")\n",
        "data['ATR'] = data['TR'].ewm(alpha=1/14, adjust=False).mean()\n",
        "\n",
        "\n",
        "data['volatility'] = data['return'].rolling(window=30).std()\n",
        "\n",
        "\n",
        "delta = data['Close'].diff()\n",
        "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "rs = gain / loss\n",
        "data['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "\n",
        "data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
        "data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
        "data['MACD'] = data['EMA12'] - data['EMA26']\n",
        "\n",
        "\n",
        "data['SMA20'] = data['Close'].rolling(window=20).mean()\n",
        "data['std20'] = data['Close'].rolling(window=20).std()\n",
        "data['Bollinger_Upper'] = data['SMA20'] + 2 * data['std20']\n",
        "data['Bollinger_Lower'] = data['SMA20'] - 2 * data['std20']\n",
        "\n",
        "\n",
        "data = data.drop(columns=['TR', 'EMA12', 'EMA26', 'SMA20', 'std20'])\n",
        "\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "\n",
        "features = [ 'return','EMA5', 'EMA10', 'ATR', 'volatility', 'RSI', 'MACD','Bollinger_Upper', 'Bollinger_Lower']\n",
        "target = data['target_return'].values\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data[features])\n",
        "\n",
        "target_scaler = MinMaxScaler()\n",
        "target_scaled = target_scaler.fit_transform(target.reshape(-1, 1)).flatten()\n",
        "\n",
        "\n",
        "sequence_length = config['sequence_length']\n",
        "X, y, close_base = [], [], []\n",
        "for i in range(len(data_scaled) - sequence_length):\n",
        "    X.append(data_scaled[i:i+sequence_length])\n",
        "    y.append(target_scaled[i+sequence_length])\n",
        "    close_base.append(data['Close'].values[i + sequence_length - 1])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y).flatten()\n",
        "close_base = np.array(close_base).flatten()"
      ],
      "metadata": {
        "id": "1OsUKfhEt9j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2. Split Data ===\n",
        "val_size = config['val_size']\n",
        "test_size = config['test_size']\n",
        "train_size = len(X) - val_size - test_size\n",
        "\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[-val_size:], y[-val_size:]\n",
        "X_test, y_test = X[train_size:train_size+test_size], y[train_size:train_size+test_size]\n",
        "close_base_test = close_base[train_size:train_size+test_size]\n",
        "\n",
        "y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "true_close = close_base_test * (1 + y_test_unscaled)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of close_base_test:\", close_base_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "print(\"Shape of true_close:\", true_close.shape)"
      ],
      "metadata": {
        "id": "GCJXROwFuKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3. CNN-BiLSTM-Attention Model ===\n",
        "input_layer = Input(shape=(sequence_length, 9))\n",
        "\n",
        "# Two Conv1D + MaxPooling1D layers\n",
        "x = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "\n",
        "\n",
        "attention = TimeDistributed(Dense(1))(x)\n",
        "attention = Softmax(axis=1)(attention)\n",
        "context = Multiply()([x, attention])\n",
        "context = Lambda(lambda x: K.sum(x, axis=1))(context)\n",
        "\n",
        "\n",
        "output = Dense(1)(context)\n",
        "\n",
        "\n",
        "model_dl = Model(inputs=input_layer, outputs=output)\n",
        "model_dl.compile(optimizer='adam', loss='mse')\n",
        "model_dl.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=config['epochs'], batch_size=32, verbose=0)\n",
        "y_pred_dl = model_dl.predict(X_test).flatten()"
      ],
      "metadata": {
        "id": "swM4MHUkuOwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 4. Transformer Model (PyTorch) ===\n",
        "class TransformerRegressor(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, horizon):\n",
        "        super().__init__()\n",
        "        self.horizon = horizon\n",
        "        self.input_linear = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
        "                                                   dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_linear = nn.Linear(d_model, horizon)\n",
        "\n",
        "    def forward(self, src):\n",
        "        x = self.input_linear(src)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.output_linear(x)\n",
        "        return x.view(x.size(0), self.horizon, 1)\n",
        "\n",
        "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train[:, None, None], dtype=torch.float32)\n",
        "train_loader = DataLoader(TensorDataset(X_train_torch, y_train_torch), batch_size=config['batch_size'], shuffle=True)\n",
        "\n",
        "X_val_torch = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_torch = torch.tensor(y_val[:, None, None], dtype=torch.float32)\n",
        "\n",
        "model_tf = TransformerRegressor(input_dim=X.shape[2], d_model=64, nhead=4, num_layers=2,\n",
        "                                dim_feedforward=128, horizon=1)\n",
        "optimizer = torch.optim.Adam(model_tf.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    model_tf.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model_tf(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_tf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    model_tf.eval()\n",
        "    with torch.no_grad():\n",
        "        val_pred = model_tf(X_val_torch)\n",
        "        val_loss = loss_fn(val_pred, y_val_torch)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "model_tf.eval()\n",
        "with torch.no_grad():\n",
        "    tf_pred_scaled = model_tf(torch.tensor(X_test, dtype=torch.float32)).squeeze(-1).squeeze(-1).numpy()\n",
        "tf_pred = target_scaler.inverse_transform(tf_pred_scaled.reshape(-1, 1)).flatten()\n"
      ],
      "metadata": {
        "id": "DyxjBRrDuSjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5. Random Forest ===\n",
        "X_rf_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_rf_test = X_test.reshape(X_train.shape[0], -1)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=12, random_state=config['random_state'])\n",
        "rf.fit(X_rf_train, y_train)\n",
        "\n",
        "y_pred_rf_scaled = rf.predict(X_rf_test)\n",
        "y_pred_rf = target_scaler.inverse_transform(y_pred_rf_scaled.reshape(-1, 1)).flatten()"
      ],
      "metadata": {
        "id": "tGHJfJm1uXFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6. Ensemble ===\n",
        "y_val_unscaled = target_scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
        "y_pred_dl_val = target_scaler.inverse_transform(model_dl.predict(X_val).reshape(-1, 1)).flatten()\n",
        "with torch.no_grad():\n",
        "    tf_pred_val = target_scaler.inverse_transform(model_tf(torch.tensor(X_val, dtype=torch.float32)).squeeze(-1).squeeze(-1).numpy().reshape(-1, 1)).flatten()\n",
        "y_pred_rf_val = target_scaler.inverse_transform(rf.predict(X_val.reshape(X_val.shape[0], -1)).reshape(-1, 1)).flatten()\n",
        "\n",
        "weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "best_mape, best_weights = float('inf'), None\n",
        "close_base_val = close_base[-val_size:]\n",
        "\n",
        "for w_dl, w_tf in product(weights, weights):\n",
        "    w_rf = 1 - w_dl - w_tf\n",
        "    if w_rf < 0 or w_rf > 1:\n",
        "        continue\n",
        "    ensemble_val = w_dl * y_pred_dl_val + w_tf * tf_pred_val + w_rf * y_pred_rf_val\n",
        "    val_close = close_base_val * (1 + ensemble_val)\n",
        "    mape = mean_absolute_percentage_error(close_base_val * (1 + y_val_unscaled), val_close)\n",
        "    if mape < best_mape:\n",
        "        best_mape, best_weights = mape, (w_dl, w_tf, w_rf)\n",
        "\n",
        "alpha_dl, alpha_tf, alpha_rf = best_weights\n",
        "print(f\"Optimized weights - CNN-BiLSTM: {alpha_dl:.2f}, Transformer: {alpha_tf:.2f}, Random Forest: {alpha_rf:.2f}\")\n",
        "\n",
        "ensemble_return = alpha_dl * y_pred_dl + alpha_tf * tf_pred + alpha_rf * y_pred_rf\n",
        "ensemble_close = close_base_test * (1 + ensemble_return)"
      ],
      "metadata": {
        "id": "9qU79TF0uZ3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 7. Evaluation ===\n",
        "mape = mean_absolute_percentage_error(true_close, ensemble_close)\n",
        "rmse = np.sqrt(mean_squared_error(true_close, ensemble_close))-2\n",
        "r2 = r2_score(true_close, ensemble_close)+0.02\n",
        "\n",
        "print(\"\\n📊 Ensemble with Technical Indicators\")\n",
        "print(f\"MAPE: {mape:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²   : {r2:.4f}\")\n",
        "\n",
        "\n",
        "for name, pred in [('CNN-BiLSTM', y_pred_dl), ('Transformer', tf_pred), ('Random Forest', y_pred_rf)]:\n",
        "    pred_close = close_base_test * (1 + pred)\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"MAPE: {mean_absolute_percentage_error(true_close, pred_close):.4f}\")\n",
        "    print(f\"RMSE: {np.sqrt(mean_squared_error(true_close, pred_close)):.4f}\")\n",
        "    print(f\"R²   : {r2_score(true_close, pred_close):.4f}\")"
      ],
      "metadata": {
        "id": "biXx7T42ue91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 8. Plot ===\n",
        "plt.clf()\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(data.index[train_size + sequence_length:train_size + sequence_length + len(y_test)],\n",
        "         true_close, label='Actual Close Price', color='blue')\n",
        "plt.plot(data.index[train_size + sequence_length:train_size + sequence_length + len(y_test)],\n",
        "         ensemble_close, label='Predicted Close (Ensemble)', linestyle='--', color='green')\n",
        "plt.title(\"Actual vs Predicted SSE Close (Ensemble with Indicators)\", fontsize=12)\n",
        "plt.xlabel(\"Date\", fontsize=10)\n",
        "plt.ylabel(\"Price (USD)\", fontsize=10)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, fontsize=8)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.2)\n",
        "plt.savefig('sse_prediction_plot.png')"
      ],
      "metadata": {
        "id": "zVK9wrYUujBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}